{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREES FOR IDENTIFYING RISKY BANK LOANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data with these characteristics is available in a dataset donated to the UCI Machine Learning Data Repository (http://archive.ics.uci.edu/ml) by Hans Hofmann of the University of Hamburg.\n",
    "\n",
    "The dataset contains information on loans obtained from a credit agency in Germany."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to continue from a previously saved session state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionfile <- \"04_decision_trees_01.RData\"\n",
    "\n",
    "if(file.exists(sessionfile)) load(sessionfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table) # to handle the data in a more convenient manner\n",
    "library(tidyverse) # for a better work flow and more tools to wrangle and visualize the data\n",
    "library(listviewer) # for navigating nested/list objects\n",
    "library(scales) # for formatting numbers\n",
    "library(C50) # for C5.0 decision tree algorithm\n",
    "library(gmodels) # for model evaluation\n",
    "library(IRdisplay) # to help pretty print tables\n",
    "options(warn = -1) # for suppressing messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data into a data.table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit <- fread(\"../data/csv/03_01_credit.csv\", stringsAsFactors = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some info on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary is result is messed. We split into numeric and factors and pretty print summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_num <- credit %>% purrr::keep(is.numeric)\n",
    "\n",
    "summaries <- credit_num %>%\n",
    "    summary() %>% # get statistical summaries\n",
    "    apply(1, function(x) stringr::str_extract(x, \"(?<=:).+\") %>% as.numeric) %>%\n",
    "    magrittr::set_colnames(names(summary(1))) %>% # set column names\n",
    "    magrittr::set_rownames(names(credit_num)) # set row names\n",
    "\n",
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprintf(\"Loan amount duration ranged between %s and %s months\", summaries[1,1], summaries[1,6])\n",
    "sprintf(\"Loan amount ranged between %s DM and %s DM\", summaries[2,1], summaries[2,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "credit %>%\n",
    "    purrr::discard(is.numeric) %>%\n",
    "    lapply(unique) %>%\n",
    "    listviewer::jsonedit(mode = \"form\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the expected 1,000 observations and 17 features, which are a combination of factor and integer data types.\n",
    "\n",
    "Let's take a look at the table() output for a couple of loan features that seem likely to predict a default.\n",
    "\n",
    "The applicant's checking and savings account balance are recorded as categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(credit$checking_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(credit$savings_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But dull numbers do not tell much of a thing.\n",
    "\n",
    "We'd better have a faceted histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_hist <- credit[,.(checking_balance, savings_balance)] %>%\n",
    "    tidyr::gather() %>%\n",
    "    ggplot(aes(x = value)) + # plot value\n",
    "    facet_wrap(~ key, scales = \"free\") + # divide into separate plots by key\n",
    "    geom_bar() +\n",
    "    coord_flip()\n",
    "    \n",
    "plotly::ggplotly(credit_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the factor levels are not sorted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapply(credit[,.(checking_balance, savings_balance)], levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reorder factors (do not run it more than once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit[, (c(\"checking_balance\", \"savings_balance\")) :=\n",
    "       .(forcats::fct_relevel(checking_balance, \"< 0 DM\") %>% factor(ordered = T),\n",
    "        forcats::fct_relevel(savings_balance, \"< 100 DM\") %>% factor(ordered = T)\n",
    "           )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(credit$checking_balance)\n",
    "str(credit$savings_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot again with combined factor level orders: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "credit_hist <- credit[,.(checking_balance, savings_balance)] %>%\n",
    "    tidyr::gather() %>%\n",
    "    ggplot(aes(x = value)) + # plot value\n",
    "    facet_wrap(~ key, scales = \"free\") + # divide into separate plots by key\n",
    "    geom_bar() +\n",
    "    scale_x_discrete(limits = c(\"< 0 DM\", \"< 100 DM\", \"1 - 200 DM\",\n",
    "                                \"100 - 500 DM\", \"> 200 DM\", \"500 - 1000 DM\", \"> 1000 DM\", \"unknown\")) +\n",
    "    coord_flip()\n",
    "    \n",
    "plotly::ggplotly(credit_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabdef <- table(credit$default)\n",
    "tabdef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprintf(\"%s of all loans defaulted\", scales::percent(prop.table(tabdef)[2], accuracy = 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And better in a visual format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotly::plot_ly(credit, x = ~default,\n",
    "        type = \"histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick train indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample <- credit[,sample(.N, 0.9 * .N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train <- credit[train_sample]\n",
    "credit_test <- credit[-train_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the no/yes distribution of train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p1 <- ggplot2::ggplot(credit_train[,.(default)]) +\n",
    "geom_bar(aes(x = default, y = ..count../sum(..count..)), height = 0.1) +\n",
    "ggtitle(\"Train Labels\") +\n",
    "labs(x = \"type\", y = \"proportion\")\n",
    "\n",
    "p2 <- ggplot2::ggplot(credit_test[,.(default)]) +\n",
    "geom_bar(aes(x = default, y = ..count../sum(..count..)), height = 0.1) +\n",
    "ggtitle(\"Test Labels\") +\n",
    "labs(x = \"default or not\", y = \"proportion\")\n",
    "\n",
    "gridExtra::grid.arrange(p1, p2, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are fairly similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_model <- C50::C5.0(credit_train[,!\"default\"], credit_train$default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprintf(\"The tree is %s decisions deep\", credit_model$size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the structure of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class(credit_model)\n",
    "str(credit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get a summary of the decision tree and view it as text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(credit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or view like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_model$output %>% cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a large tree is too much compute intensive, so we skip that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret the first three levels:\n",
    "The numbers xxx/yyy means: xxx examples reaches the decision and yyy are incorrectly classified\n",
    "\n",
    "* If checking balance is either unknown or > 200, classify 411 (56 incorrect) as \"no default\" (this is a leaf)\n",
    "* If checking balance is < 200, then;\n",
    "    * If months loan duration  > 30, then;\n",
    "        * If unemployed classify 6 (all correct) as \"no default\" (this may be an anomaly)\n",
    "        * If employed, then;\n",
    "            * Age <= 25, classify 15 (all correct) as \"likely to default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix at the end of the summary shows the classification accuracy of the model on the train set itself.\n",
    "\n",
    "But it is better we create the confusion matrix ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_result <- predict(credit_model, credit_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt1 <- gmodels::CrossTable(credit_train$default, credit_result, prop.chisq = F, prop.c = F, prop.r = F,\n",
    "dnn = c('actual default', 'predicted default'))\n",
    "\n",
    "ct_dt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the cross table is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(ct_dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the overal accuracy of the model and format as a percent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt1$prop.tbl %>%\n",
    "    diag() %>%\n",
    "    sum() %>%\n",
    "    scales::percent(accuracy = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model and evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the model on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_pred <- predict(credit_model, credit_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And report confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt2 <- gmodels::CrossTable(credit_test$default, credit_pred, prop.chisq = F, prop.c = F, prop.r = F,\n",
    "dnn = c('actual default', 'predicted default'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt2$prop.tbl %>%\n",
    "    diag() %>%\n",
    "    sum() %>%\n",
    "    scales::percent(accuracy = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sprintf(\"%s of %s actual defaults not predicted!\", ct_dt2$t[2,1], sum(ct_dt2$t[2,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive boosting is a process in which many decision trees are built and the trees vote on the best class for each example.\n",
    "\n",
    "Boosting is rooted in the notion that by combining a number of weak performing learners, you can create a team that is much stronger than any of the learners alone. Each of the models has a unique set of strengths and weaknesses and they may be better or worse in solving certain problems. Using a combination of several learners with complementary strengths and weaknesses can therefore dramatically improve the accuracy of a classifier.\n",
    "\n",
    "The C5.0() function makes it easy to add boosting to our C5.0 decision tree. We simply need to add an additional trials parameter indicating the number of separate decision trees to use in the boosted team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_boost10 <- C5.0(credit_train[,-\"default\"],\n",
    "                       credit_train$default,\n",
    "                       trials = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_boost10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(credit_boost10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_result_boost10 <- predict(credit_boost10, credit_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt3 <- gmodels::CrossTable(credit_train$default, credit_result_boost10, prop.chisq = F, prop.c = F, prop.r = F,\n",
    "dnn = c('actual default', 'predicted default'))\n",
    "\n",
    "ct_dt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt3$prop.tbl %>%\n",
    "    diag() %>%\n",
    "    sum() %>%\n",
    "    scales::percent(accuracy = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on the train data enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_pred_boost10 <- predict(credit_boost10, credit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt4 <- gmodels::CrossTable(credit_test$default, credit_pred_boost10, prop.chisq = F, prop.c = F, prop.r = F,\n",
    "dnn = c('actual default', 'predicted default'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or nicely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt4$t %>% knitr::kable() %>% as.character() %>% IRdisplay::display_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt4$prop.tbl %>%\n",
    "    diag() %>%\n",
    "    sum() %>%\n",
    "    scales::percent(accuracy = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting did not help on test set. We can play with more iterations or use other methods to enhance performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making mistakes costlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C5.0 algorithm allows us to assign a penalty to different types of errors, in order to discourage a tree from making more costly mistakes. The penalties are designated in a cost matrix, which specifies how much costlier each error is, relative to any other prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimnames <- rep(list(c(\"no\", \"yes\")), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(dimnames) <- c(\"predicted\", \"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cost <- matrix(c(0,1,4,0), nrow = 2, dimnames = dimnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a wrong classification incurs a cost while a correct one does not\n",
    "\n",
    "Now, let's apply it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_cost <- C50::C5.0(credit_train[-17],\n",
    "                         credit_train$default,\n",
    "                         costs = error_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_cost_pred <- predict(credit_cost, credit_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt5 <- gmodels::CrossTable(credit_test$default,\n",
    "                    credit_cost_pred,\n",
    "                    prop.chisq = FALSE,\n",
    "                    prop.c = FALSE,\n",
    "                    prop.r = FALSE,\n",
    "                    dnn = c('actual default', 'predicted default'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dt5$prop.tbl %>%\n",
    "    diag() %>%\n",
    "    sum() %>%\n",
    "    scales::percent(accuracy = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy is lower. However:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprintf(\"%s of %s actual defaults not predicted!\", ct_dt5$t[2,1], sum(ct_dt5$t[2,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So false negatives are much lower with cost matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save.image(sessionfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
