{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(data.table)\n",
    "library(plotly) # for interactive ploting\n",
    "library(DT) # for interactive tabulation\n",
    "library(broom) # for tidy statistical summaries\n",
    "library(caret) # for regression performance measures\n",
    "library(psych) # for pairwise comparisons\n",
    "library(GGally) # for pairwise comparisons\n",
    "library(magrittr) # for two-way pipes\n",
    "library(lindia) # for qqplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows=20, repr.matrix.max.cols=15) # for limiting the number of top and bottom rows of tables printed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath <- \"~/data_ad454\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-motion",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-expert",
   "metadata": {},
   "source": [
    "In this session we will include more than one independent variables for multiple linear regression.\n",
    "\n",
    "We will split the dataset into train and test partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-suite",
   "metadata": {},
   "source": [
    "Let's first import the realty dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data <- readRDS(sprintf(\"%s/rds/02_01_realty_data.rds\", datapath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-heavy",
   "metadata": {},
   "source": [
    "Let's see the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-basketball",
   "metadata": {},
   "source": [
    "You can navigate through and filter the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% datatable(\n",
    "  filter = \"top\",\n",
    "  options = list(pageLength = 20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-denver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "measured-premiere",
   "metadata": {},
   "source": [
    "See which variables are of factor type and what the levels of each are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% keep(is.factor) %>% lapply(levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-induction",
   "metadata": {},
   "source": [
    "And the frequencies of those levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% keep(is.factor) %>% summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-challenge",
   "metadata": {},
   "source": [
    "Let's see the numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% keep(is.numeric) %>% names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-drinking",
   "metadata": {},
   "source": [
    "And statistical summaries of numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% keep(is.numeric) %>% summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-trigger",
   "metadata": {},
   "source": [
    "And statistical summaries of numeric columns in a better format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% keep(is.numeric) %>% broom::tidy() %>% mutate_if(is.numeric, round, 2) %>%\n",
    "select(column, n, mean, sd, median, min, max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-dollar",
   "metadata": {},
   "source": [
    "And the boolean (logical) variables showing which features exist or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% keep(is.logical) %>% names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-tanzania",
   "metadata": {},
   "source": [
    "Frequencies of boolean and NA values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% keep(is.logical) %>% summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-morrison",
   "metadata": {},
   "source": [
    "Frequencies of boolean and NA values in a better format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "do.call(rbind, realty_data %>% keep(is.logical) %>% \n",
    "lapply(table, useNA = \"always\")) %>%\n",
    "datatable(\n",
    "  filter = \"top\",\n",
    "  options = list(pageLength = 20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-living",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-enough",
   "metadata": {},
   "source": [
    "Now let's clean some of the categoric and boolean variables:\n",
    "\n",
    "Some categories or variables actually point at similar things, so they better be integrated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data[isinma_tipi == \"merkezi (pay olcer)\", isinma_tipi := \"merkezi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data[, su_deposu := su_deposu | hidrofor]\n",
    "realty_data[, hidrofor := NULL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data[, isi_yalitim := isi_yalitim | isicam]\n",
    "realty_data[, isicam := NULL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data[, saten_boya := saten_boya | saten_alci]\n",
    "realty_data[, saten_alci := NULL]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-kansas",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-difference",
   "metadata": {},
   "source": [
    "Now let's select some of the boolean variables.\n",
    "\n",
    "First take out direction variables since they have missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% keep(is.logical) %>% select(-c(\"kuzey\", \"bati\", \"guney\", \"dogu\")) %>% length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-prompt",
   "metadata": {},
   "source": [
    "See the distribution of rows in terms of how many boolean columns the ad has TRUE values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data %>% keep(is.logical) %>% select(-c(\"kuzey\", \"bati\", \"guney\", \"dogu\")) %>% rowSums %>% table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-replication",
   "metadata": {},
   "source": [
    "128 of the rows has no boolean values while only 5 rows has a single boolean value.\n",
    "\n",
    "It is highly probable that, for the ads with no boolean values, the ad owners did not take their times to select any choices, not that the property does not have those features. They can be filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "bools <- realty_data %>% keep(is.logical) %>% select(-c(\"kuzey\", \"bati\", \"guney\", \"dogu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-consideration",
   "metadata": {},
   "source": [
    "A feature that appears in too many or too few ads is not very useful. So we better select those ones that are more balanced in TRUE and FALSE values - number of TRUE cases closer to half the total number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "normx <- bools[,.N] / 2\n",
    "normx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "bools_select <- bools %>% \n",
    "colSums %>% # get total count of TRUE values\n",
    "\"-\"(normx) %>% # subtract from half of row count\n",
    "abs %>% # take absolute value\n",
    "sort %>% #sort\n",
    ".[. <= normx / 2] %>% # filter for those variables where the absolute difference if less than or equal to the quarter of total row count \n",
    "names %>% # get the names\n",
    "str_subset(\"yakin\", negate = T) %>% # there are many columns for proximity to central places. Every property around mecidiyekoy is close to the center. take them out \n",
    "setdiff(\"merkezde\") # same goes for this column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-allowance",
   "metadata": {},
   "source": [
    "See whether these columns are highly correlated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a correlation matrix\n",
    "cor0 <- realty_data %>% select(all_of(bools_select)) %>% cor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-suspect",
   "metadata": {},
   "source": [
    "Caret has a method to detect high correlations but not so useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor0 %>% caret::findCorrelation(cutoff = 0.5, verbose = T, exact = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-commissioner",
   "metadata": {},
   "source": [
    "Manuallt we can do it better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the upper triangle and off diagonal values to eliminate duplicates\n",
    "cor0[row(cor0) >= col(cor0)] <- NA\n",
    "cor0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor0 %>% as.data.table(keep.rownames = T) %>%\n",
    "gather(\"key\", \"value\", -\"rn\", na.rm = T) %>% as.data.table %>% # convert to long format data.table\n",
    "arrange(-value) %>%\n",
    "filter(value > 0.5) # filter for higher correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-second",
   "metadata": {},
   "source": [
    "No more semantically close variables with very high correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-sucking",
   "metadata": {},
   "source": [
    "Now let's select some of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "features <- c(\"price\",\n",
    "              \"neighborhood\",\n",
    "              \"esyali\",\n",
    "             \"krediye_uygunluk\",\n",
    "              \"isinma_tipi\",\n",
    "             \"kullanim_durumu\",\n",
    "              \"brut_metrekare\",\n",
    "              \"oda\",\n",
    "              \"salon\",\n",
    "              \"bina_yasi\",\n",
    "              \"banyo_sayisi\",\n",
    "              \"kat_sayisi\",\n",
    "              \"kat\", bools_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-northern",
   "metadata": {},
   "source": [
    "We calculate the row sum for all booelan variables to filter out properties with no features set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nboolean <- realty_data %>% keep(is.logical) %>% select(-c(\"kuzey\", \"bati\", \"guney\", \"dogu\")) %>% rowSums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data2 <- realty_data %>%\n",
    "select(all_of(features)) %>%\n",
    "mutate(nboolean = nboolean) %>%\n",
    "mutate(unit_price = price / brut_metrekare) %>%\n",
    "mutate(unit_size = brut_metrekare / kat) %>% # this feature controls for the land share of the property\n",
    "na.omit %>%\n",
    "filter(unit_price %between% quantile(unit_price, c(0.05, 0.95))) %>%\n",
    "filter(nboolean != 0) %>%\n",
    "filter(isinma_tipi %in% c(\"merkezi\", \"kombi\", \"kat kaloriferi\")) %>% # other categories are very rare, better to take out\n",
    "select(-c(\"price\", \"nboolean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data2 %>% str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-tunnel",
   "metadata": {},
   "source": [
    "Now let's see the correlations after the transformations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-founder",
   "metadata": {},
   "source": [
    "What model.matrix does is to create a numeric representation of the data according to the regression model.\n",
    "\n",
    "The good thing is that, it automatically converts categoric variables to sets of dummies excluding one category from each factor variable to handle linear dependency:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-accent",
   "metadata": {},
   "source": [
    "The -1 term excludes the intercept from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 <- model.matrix(unit_price ~ . - 1, realty_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(dat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-stroke",
   "metadata": {},
   "source": [
    "Same method for detecting high correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor1 <- dat1 %>% cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor1[row(cor1) >= col(cor1)] <- NA\n",
    "cor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor1 %>% as.data.table(keep.rownames = T) %>%\n",
    "gather(\"key\", \"value\", -\"rn\", na.rm = T) %>% as.data.table %>%\n",
    "arrange(-value) %>%\n",
    "filter(value > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-collector",
   "metadata": {},
   "source": [
    "It seems we better keep only brut_metrekare and exclude the other two:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-signal",
   "metadata": {},
   "source": [
    "The two way pipe makes a transformation and assigns back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data2 %<>% select(-c(\"oda\", \"banyo_sayisi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-agency",
   "metadata": {},
   "source": [
    "## Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-contract",
   "metadata": {},
   "source": [
    "Let's determine a ratio for train partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1000)\n",
    "train_ratio <- 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-hostel",
   "metadata": {},
   "source": [
    "Randomly create row indices for train partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices <- realty_data2[,sample(.N * train_ratio)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-debut",
   "metadata": {},
   "source": [
    "Split the data into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data <- realty_data2[train_indices]\n",
    "test_data <- realty_data2[-train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-forum",
   "metadata": {},
   "source": [
    "Check whether partitions are mutually exclusive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data2[,.N]\n",
    "train_data[,.N]\n",
    "test_data[,.N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-craft",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-respect",
   "metadata": {},
   "source": [
    "First include all variables without the intercept term. \".\" is a shorthand for all variables except the RHS variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 <- lm(unit_price ~ . - 1, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 %>% summary\n",
    "\n",
    "model1 %>% tidy %>% filter(p.value < 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-nudist",
   "metadata": {},
   "source": [
    "The best source to learn the easy domain specific language of formulae in R is the built-in help. Please check the details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "?formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-gabriel",
   "metadata": {},
   "source": [
    "qqplot shows whether the residual terms are distributed normally. Ideally they should be plotted across the red line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_qqplot(model1, scale.factor = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-stylus",
   "metadata": {},
   "source": [
    "They deviate from the line so normality assumption is breached"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-boutique",
   "metadata": {},
   "source": [
    "Compare predictions and actual values for train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 5, repr.plot.height = 5)\n",
    "\n",
    "actual_train <- train_data$unit_price\n",
    "predicted_train <- predict(model1, train_data)\n",
    "\n",
    "actual_test <- test_data$unit_price\n",
    "predicted_test <- predict(model1, test_data)\n",
    "\n",
    "model_dt <- data.table(partition = c(\"train\", \"test\"),\n",
    "                       R2 = c(R2(predicted_train, actual_train),\n",
    "                                R2(predicted_test, actual_test)),\n",
    "                        RMSE = c(RMSE(predicted_train, actual_train),\n",
    "                                 RMSE(predicted_test, actual_test)),\n",
    "                        MAE = c(MAE(predicted_train, actual_train),\n",
    "                                MAE(predicted_test, actual_test))\n",
    "                        )\n",
    "\n",
    "model_dt\n",
    "\n",
    "data.table(actual = actual_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Train Actual vs. Predictions\")\n",
    "\n",
    "data.table(actual = actual_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Test Actual vs. Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.table(residuals = actual_train - predicted_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "ggtitle(\"Train Predictions vs. Residuals\")\n",
    "\n",
    "data.table(residuals = actual_test - predicted_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "ggtitle(\"Test Predictions vs. Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-hardware",
   "metadata": {},
   "source": [
    "The multiple R2 of the model is very high while the squared correlations between actual and predicted values are much lower. Why?\n",
    "\n",
    "In fact the neighborhood defines the level of the unit price to a great extent and the prices vary much across the neighborhoods. What the model shows is the wide range of differences in the prices across the neighborhoods. So the variance is not uniform across the set but clusters around different neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-expression",
   "metadata": {},
   "source": [
    "We better calculate the deviation of the unit price from the median unit price of the neighborhood or the premium as a percentage:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-sleeping",
   "metadata": {},
   "source": [
    "## Premium by neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_av <- realty_data2[, .(price_neigh = median(unit_price)), by = neighborhood]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data3 <- neigh_av[realty_data2, on = \"neighborhood\"] %>% # merge the data.table way\n",
    "mutate(premium_neigh = unit_price / price_neigh -1) %>% # calculate the premium\n",
    "select(-c(\"unit_price\", \"price_neigh\", \"neighborhood\")) %>%\n",
    "filter(premium_neigh %between% quantile(premium_neigh, c(0.1, 0.9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-arctic",
   "metadata": {},
   "source": [
    "We partition again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1000)\n",
    "train_ratio <- 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-killing",
   "metadata": {},
   "source": [
    "Randomly create row indices for train partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices2 <- realty_data3[,sample(.N * train_ratio)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-garlic",
   "metadata": {},
   "source": [
    "Split the data into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 <- realty_data3[train_indices2]\n",
    "test_data2 <- realty_data3[-train_indices2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-zambia",
   "metadata": {},
   "source": [
    "Check whether partitions are mutually exclusive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data3[,.N]\n",
    "train_data2[,.N]\n",
    "test_data2[,.N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-silver",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-removal",
   "metadata": {},
   "source": [
    "Now let's try to explain the premium using all variables at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 <- lm(premium_neigh ~ ., train_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 %>% summary\n",
    "model2 %>% tidy %>% filter(p.value < 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 5, repr.plot.height = 5)\n",
    "\n",
    "actual_train <- train_data2$premium_neigh\n",
    "predicted_train <- predict(model2, train_data2)\n",
    "\n",
    "actual_test <- test_data2$premium_neigh\n",
    "predicted_test <- predict(model2, test_data2)\n",
    "\n",
    "model_dt <- data.table(partition = c(\"train\", \"test\"),\n",
    "                       R2 = c(R2(predicted_train, actual_train),\n",
    "                                R2(predicted_test, actual_test)),\n",
    "                        RMSE = c(RMSE(predicted_train, actual_train),\n",
    "                                 RMSE(predicted_test, actual_test)),\n",
    "                        MAE = c(MAE(predicted_train, actual_train),\n",
    "                                MAE(predicted_test, actual_test))\n",
    "                        )\n",
    "\n",
    "model_dt\n",
    "\n",
    "data.table(actual = actual_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Train Actual vs. Predictions\")\n",
    "\n",
    "data.table(actual = actual_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Test Actual vs. Predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-packet",
   "metadata": {},
   "source": [
    "The predictive performance is not still very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_qqplot(model2, scale.factor = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-singer",
   "metadata": {},
   "source": [
    "Residuals closer to normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.table(residuals = actual_train - predicted_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "ggtitle(\"Train Predictions vs. Residuals\")\n",
    "\n",
    "data.table(residuals = actual_test - predicted_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "ggtitle(\"Test Predictions vs. Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-contractor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regular-proof",
   "metadata": {},
   "source": [
    "## Pairwise comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-musician",
   "metadata": {},
   "source": [
    "Now let's try to detect non-linear relationships using some alternative and similar methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs(train_data2 %>% keep(is.numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.panels(train_data2 %>% keep(is.numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggpairs(train_data2 %>% keep(is.numeric))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-custody",
   "metadata": {},
   "source": [
    "## Model with quadratic terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-luther",
   "metadata": {},
   "source": [
    "There might be a quadratic linearship between bina_yasi and premium:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-squad",
   "metadata": {},
   "source": [
    "However if we add this quadratic term manually, there might be multicollinarity with the linear term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(realty_data3 %>% select(bina_yasi) %>% mutate(binayasi2 = bina_yasi^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-spanking",
   "metadata": {},
   "source": [
    "But the poly() function does that creating orthagonal terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "realty_data3[, poly(bina_yasi, 2)] %>% cor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-prime",
   "metadata": {},
   "source": [
    "Since \".\" includes all terms, bina_yasi is subtracted to prevent double accounting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 <- lm(premium_neigh ~ . - bina_yasi + poly(bina_yasi, 2), train_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 %>% summary\n",
    "model3 %>% tidy %>% filter(p.value < 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 5, repr.plot.height = 5)\n",
    "gg_qqplot(model3, scale.factor = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_train <- train_data2$premium_neigh\n",
    "predicted_train <- predict(model3, train_data2)\n",
    "\n",
    "actual_test <- test_data2$premium_neigh\n",
    "predicted_test <- predict(model3, test_data2)\n",
    "\n",
    "model_dt <- data.table(partition = c(\"train\", \"test\"),\n",
    "                       R2 = c(R2(predicted_train, actual_train),\n",
    "                                R2(predicted_test, actual_test)),\n",
    "                        RMSE = c(RMSE(predicted_train, actual_train),\n",
    "                                 RMSE(predicted_test, actual_test)),\n",
    "                        MAE = c(MAE(predicted_train, actual_train),\n",
    "                                MAE(predicted_test, actual_test))\n",
    "                        )\n",
    "\n",
    "model_dt\n",
    "\n",
    "data.table(actual = actual_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Train Actual vs. Predictions\")\n",
    "\n",
    "data.table(actual = actual_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Test Actual vs. Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.table(residuals = actual_train - predicted_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "geom_hline(yintercept = 0) +\n",
    "ggtitle(\"Train Predictions vs. Residuals\")\n",
    "\n",
    "data.table(residuals = actual_test - predicted_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "geom_hline(yintercept = 0) +\n",
    "ggtitle(\"Test Predictions vs. Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-completion",
   "metadata": {},
   "source": [
    "Performance still not good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-discussion",
   "metadata": {},
   "source": [
    "## Model with fewer variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-yesterday",
   "metadata": {},
   "source": [
    "Let's select only those variables from the previous model that are significant at 10% level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 <- lm(premium_neigh ~ esyali + krediye_uygunluk +\n",
    "             salon + poly(bina_yasi, 2) +\n",
    "             manzara_sehir +\n",
    "             pvc_dograma +\n",
    "             goruntulu_diafon +\n",
    "             cadde_uzerinde +\n",
    "             su_deposu,\n",
    "             train_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 %>% summary\n",
    "model4 %>% tidy %>% filter(p.value < 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_qqplot(model4, scale.factor = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 5, repr.plot.height = 5)\n",
    "\n",
    "actual_train <- train_data2$premium_neigh\n",
    "predicted_train <- predict(model4, train_data2)\n",
    "\n",
    "actual_test <- test_data2$premium_neigh\n",
    "predicted_test <- predict(model4, test_data2)\n",
    "\n",
    "model_dt <- data.table(partition = c(\"train\", \"test\"),\n",
    "                       R2 = c(R2(predicted_train, actual_train),\n",
    "                                R2(predicted_test, actual_test)),\n",
    "                        RMSE = c(RMSE(predicted_train, actual_train),\n",
    "                                 RMSE(predicted_test, actual_test)),\n",
    "                        MAE = c(MAE(predicted_train, actual_train),\n",
    "                                MAE(predicted_test, actual_test))\n",
    "                        )\n",
    "\n",
    "model_dt\n",
    "\n",
    "data.table(actual = actual_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Train Actual vs. Predictions\")\n",
    "\n",
    "data.table(actual = actual_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Test Actual vs. Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.table(residuals = actual_train - predicted_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "geom_hline(yintercept = 0) +\n",
    "ggtitle(\"Train Predictions vs. Residuals\")\n",
    "\n",
    "data.table(residuals = actual_test - predicted_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "geom_hline(yintercept = 0) +\n",
    "ggtitle(\"Test Predictions vs. Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-police",
   "metadata": {},
   "source": [
    "## Model with interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-institute",
   "metadata": {},
   "source": [
    "Now let's add interactions terms among variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 <- lm(premium_neigh ~ (esyali + krediye_uygunluk +\n",
    "             salon + poly(bina_yasi, 2) +\n",
    "             manzara_sehir +\n",
    "             goruntulu_diafon)*su_deposu,\n",
    "             train_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 %>% summary\n",
    "model5 %>% tidy %>% filter(p.value < 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_qqplot(model5, scale.factor = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 5, repr.plot.height = 5)\n",
    "\n",
    "actual_train <- train_data2$premium_neigh\n",
    "predicted_train <- predict(model5, train_data2)\n",
    "\n",
    "actual_test <- test_data2$premium_neigh\n",
    "predicted_test <- predict(model5, test_data2)\n",
    "\n",
    "model_dt <- data.table(partition = c(\"train\", \"test\"),\n",
    "                       R2 = c(R2(predicted_train, actual_train),\n",
    "                                R2(predicted_test, actual_test)),\n",
    "                        RMSE = c(RMSE(predicted_train, actual_train),\n",
    "                                 RMSE(predicted_test, actual_test)),\n",
    "                        MAE = c(MAE(predicted_train, actual_train),\n",
    "                                MAE(predicted_test, actual_test))\n",
    "                        )\n",
    "\n",
    "model_dt\n",
    "\n",
    "data.table(actual = actual_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Train Actual vs. Predictions\")\n",
    "\n",
    "data.table(actual = actual_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = actual, y = predictions)) +\n",
    "geom_point() +\n",
    "geom_abline(slope = 1, intercept = 0) +\n",
    "ggtitle(\"Test Actual vs. Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.table(residuals = actual_train - predicted_train, predictions = predicted_train) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "geom_hline(yintercept = 0) +\n",
    "ggtitle(\"Train Predictions vs. Residuals\")\n",
    "\n",
    "data.table(residuals = actual_test - predicted_test, predictions = predicted_test) %>%\n",
    "ggplot(aes(x = predictions, y = residuals)) +\n",
    "geom_point() +\n",
    "geom_hline(yintercept = 0) +\n",
    "ggtitle(\"Test Predictions vs. Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-actor",
   "metadata": {},
   "source": [
    "The model performs better on train set while the performance is worse on test set. The model memorized the data, instead of learning it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-telephone",
   "metadata": {},
   "source": [
    "## Multi collinearity check for the last time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-vietnam",
   "metadata": {},
   "source": [
    "Caret way:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "inappropriate-treasury",
   "metadata": {},
   "source": [
    "model.matrix(model4)[,-1] %>% cor %>% caret::findCorrelation(cutoff = 0.5, exact = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-candidate",
   "metadata": {},
   "source": [
    "Manual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor2 <- model.matrix(model4) %>% cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the upper triangle and off diagonal values to eliminate duplicates\n",
    "cor2[row(cor2) >= col(cor2)] <- NA\n",
    "cor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor2 %>% as.data.table(keep.rownames = T) %>%\n",
    "gather(\"key\", \"value\", -\"rn\", na.rm = T) %>% as.data.table %>% # convert to long format data.table\n",
    "arrange(-value) %>%\n",
    "filter(value > 0.5) # filter for higher correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-burden",
   "metadata": {},
   "source": [
    "No high correlations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
