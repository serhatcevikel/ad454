{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression model on handaxe dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is adapted from Lewis (2017) Chapter 6\n",
    "\n",
    "In this example, we build a linear regression model to predict the maximum length of a Lower Paleolithic hand axe.\n",
    "\n",
    "The Handaxes data-frame contains 600 measurements on Lower Paleolithic hand-axes from Furze Platt, Berkshire, England."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table) # to handle the data in a more convenient manner\n",
    "library(tidyverse) # for a better work flow and more tools to wrangle and visualize the data\n",
    "library(plotly) # for interactive visualizations\n",
    "library(psych) # for visualizing relationship among pairs of variables\n",
    "library(GGally) # for better visualizing relationship among pairs of variables\n",
    "library(corrplot) # for correlation plots\n",
    "library(listviewer) # for visualizing nested data structures\n",
    "library(caret) # for detecting highly correlated variables\n",
    "library(broom) # for getting a glance of model fit\n",
    "library(TSrepr) # for evaluating predictive power\n",
    "library(archdata) # for handaxe data\n",
    "library(lindia) # for regression model diagnostics\n",
    "library(lmtest) # for variance, auto-correlation, and coefficient significance tests\n",
    "library(car) # for variance and multi-collinearity tests\n",
    "library(mctest) # for multi-collinearity tests\n",
    "library(ppcor) # for partial correlations\n",
    "library(fit.models) # for comparing models\n",
    "library(MASS) # for robust regression\n",
    "library(forecast) # for auto-correlation plots\n",
    "options(warn = -1) # for suppressing messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(\"Handaxes\",package=\"archdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?Handaxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Format\n",
    "A data frame with 600 observations on the following 8 variables.\n",
    "\n",
    "Catalog\n",
    "Specimen catalog number\n",
    "\n",
    "L\n",
    "Maximum Length\n",
    "\n",
    "L1\n",
    "Distance from the butt to the location of the maximum breadth measured along the length dimension\n",
    "\n",
    "B\n",
    "Maximum breadth\n",
    "\n",
    "B1\n",
    "Breadth measured at 1/5 of the length from the tip. Measured perpendicular to the length\n",
    "\n",
    "B2\n",
    "Breadth measured at 1/5 of the length from the butt. Measured perpendicular to the length\n",
    "\n",
    "T\n",
    "Maximum thickness, not necessarily measured at the maximum breadth\n",
    "\n",
    "T1\n",
    "Thickness measured at B1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L variable will be our dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handaxes_dt <- as.data.table(Handaxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(handaxes_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handaxes_dt %>% purrr::keep(is.numeric) %>% sapply(quantile) %>% t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handaxes_dt %>% purrr::keep(is.numeric) %>% # select columns\n",
    "    tidyr::gather() %>% # reshape into long format in columns \"key\" and \"value\"\n",
    "    ggplot(aes(value)) + # plot value\n",
    "        facet_wrap(~ key, scale = \"free\" ) + # divide into separate plots by key\n",
    "        geom_density(fill = \"green\")  # get density plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handaxes_dt %>% purrr::keep(is.numeric) %>% psych::pairs.panels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handaxes_dt %>% purrr::keep(is.numeric) %>% GGally::ggpairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handaxes_dt %>% purrr::keep(is.numeric) %>% cor() %>%\n",
    "\n",
    "corrplot::corrplot.mixed(upper = \"ellipse\",\n",
    "                         lower = \"number\",\n",
    "                         tl.pos = \"lt\",\n",
    "                         number.cex = .5,\n",
    "                         lower.col = \"black\",\n",
    "                         tl.cex = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables are normally distributed. Some of the dependent variables are highly correlated as B and B2, L1 and B1 pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y <- handaxes_dt[,log(L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample <- handaxes_dt[,log(.SD), .SDcols = L1:T1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing multi-collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can address multi-collinearity by removing highly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_matrix <- data_sample %>% cor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid_col <- caret::findCorrelation(cor_matrix, cutoff = 0.6, exact = F)\n",
    "rid_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_vars <- colnames(data_sample)[rid_col]\n",
    "remove_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample2 <- data_sample[,-c(remove_vars), with = F]\n",
    "data_sample2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2016)\n",
    "train_ind <- data_sample2[,sample(.I, 550)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train <- y[train_ind]\n",
    "y_test <- y[-train_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train <- data_sample2[train_ind]\n",
    "data_test <- data_sample2[-train_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[,.N]\n",
    "data_test[,.N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 1:**\n",
    "\n",
    "Create a model called \"fit1\" using all the variables in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**SOLUTION 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "fit1 <- lm( y_train ~., data = data_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1_sum <- summary(fit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "listviewer::jsonedit(fit1, mode = \"form\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listviewer::jsonedit(fit1_sum, mode = \"form\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1_sum$coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minus sign on T1's coefficient is weird since the correlation between T1 and L1 is positive!\n",
    "\n",
    "We drop it from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 <- lm(y_train ~ L1 + B2 + T, data = data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2_sum <- summary(fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2_sum$coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables are significant(ly different than 0) as per their p values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glance of model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broom::glance(fit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F statistic is highly significant. However r squared value could be higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance Inflation Factor (VIF) is a measure for detecting multi-collinearity\n",
    "\n",
    "> The general rule of thumb is that VIFs exceeding 4 warrant further investigation, while VIFs exceeding 10 are signs of serious multicollinearity requiring correction\n",
    "\n",
    "(https://onlinecourses.science.psu.edu/stat501/node/347/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "car::vif(fit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No VIF value in the model is sufficiently high for us to be alert for multicollinearity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative method to check for multicollinearity is Overall Multicollinearity Diagnostics from mctest package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mctest::omcdiag(data_train[,.(L1, B2, T)], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for further inspection we will use All Individual Multicollinearity Diagnostics Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mctest::imcdiag(data_train[,.(L1, B2, T)], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the output, we should not care for multi-collinearity in any of the individual variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, for examining the pattern of multicollinearity, it is required to conduct t-test for correlation coefficient.\n",
    "\n",
    "- We’ll use the ‘ppcor’ package to compute the partial correlation coefficients along with the t-statistic and corresponding p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppcor::pcor(data_train[,.(L1, B2, T)], method = \"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant partial correlation between L1 and T variables. However since VIF and other multi-collinearity diagnostics did not alert us for a problematic case, we do not exclude any of these variables.\n",
    "\n",
    "Partial correlations will be used as a confirmatory test in case significant multi-collinearity is detected in previous tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may assess the normality of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2$residuals %>% as.data.table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2$residuals %>% as.data.table() %>%\n",
    "ggplot(aes(.)) + # plot value\n",
    "    geom_density(fill = \"green\")  # get density plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a qq plot will confirm the normality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lindia::gg_qqplot(fit2, scale.factor = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Normal Q-Q plot the ordered residuals (y-axis) are plotted against the expected quantiles from a standard normal distribution function (x-axis).\n",
    "\n",
    "The plotted points should lie on an upward sloping (45 degree) straight line.\n",
    "qqplot shows the residual points fall approximately along a straight upward sloping line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last we can conduct a Shapiro-Wilk normality test on residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro.test(fit2$residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis is that the residuals are from a normal distribution.\n",
    "\n",
    "The p-value of the test statistic, at 0.81, is rather large (maximum value =1), and we cannot reject the null hy-\n",
    "pothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heteroskedasticity: Is variance constant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heteroskedasticity (non-constant variance) causes the estimated standard error of the estimates to be wrong. This means\n",
    "the confidence intervals and hypotheses tests may not be reliable. The scale-location plot is useful for assessing the constantvariance assumption.\n",
    "\n",
    "You can view the plot by setting which=3 in the plot function or gg_scalelocation function from the lindia package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lindia::gg_scalelocation(fit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be no discernible pattern to the plot with the points spread evenly around a horizontal line.\n",
    "\n",
    "Looking closely at the figure, the points seem to form a homogeneous cloud, equally spread on both sides of the line. This is good.\n",
    "\n",
    "However, there is a slight upward slope to the line, this is a little worrying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will conduct two tests for non-constant variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtest::bptest(fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car::ncvTest(fit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both statistical tests the p-value is less than 0.01, and we reject the null hypothesis of constant variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heteroskedasticity impacts the standard errors, not the estimated values.\n",
    "\n",
    "Our real concern is to ensure the coefficients in the model are statistically significant (they probably are given their tiny original p-values, but we should double check)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular solution for heteroscedasticity, involves adjusting the standard errors to better refl\n",
    "ect the actual underlying probabilities for hypothesis testing.\n",
    "\n",
    "The car package has the function hccm that does the job. It calculates the heteroscedasticity-corrected covariance matrix from which the standard errors are derived.\n",
    "\n",
    "We combine it with coeftest function from the lmtest package to recalculate the significance of coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtest::coeftest(fit2, vcov = car::hccm(fit2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, given the level of heteroskedasticity, the coefficients are still significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influential observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to check for influential observations. These are observations that greatly impact the slope of the regression line. \n",
    "\n",
    "A good way to identify problematic data points is via leverage.\n",
    "\n",
    "The leverage of an observation measures how far away it is from the other observations. It takes values between 0 and 1.\n",
    "\n",
    "A point with zero leverage has no effect on the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev <- fit2 %>% model.matrix() %>% hat()\n",
    "summary(lev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the largest value is relatively small, at 0.04. To identify this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which.max(lev)\n",
    "data_train[which.max(lev)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The influencePlot from car package also shows influential observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car::influencePlot(fit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the influencePlot function also reports Cook’s distance, this metric identifies points which have\n",
    "more influence than other points. Influence is the amount that a data point is affecting the regression line, measured by how\n",
    "much the regression line would change if the point were excluded from the regression model.\n",
    "\n",
    "Points with a large Cook’s distance have a high influence, and might require further investigation.\n",
    "\n",
    "A visual representation of Cook’s distance is obtained via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lindia::gg_cooksd(fit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points identified in Figure 6.7, or Figure 6.8 are not necessarily definitive.\n",
    "\n",
    "The key is whether excluding these points will have a significant impact on the regression coefficients.\n",
    "\n",
    "In our case, we have identified a handful of potential observations, none of which appear particularly extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to assess whether our intuition is correct, is to reestimate the model using robust regression, and then check to\n",
    "see whether the coefficient estimates are similar.\n",
    "\n",
    "If they are, then we can leave keep the identified examples in our analysis.\n",
    "\n",
    "If not, you would re-run your regression model, dropping each potential influential observation one at a time, and then assess the impact on the coefficients.\n",
    "\n",
    "Observations that significantly impact the regression coefficients can be excluded from further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Robust regression is an alternative to least squares regression when data are contaminated with outliers or influential observations, and it can also be used for the purpose of detecting influential observations.\n",
    "```\n",
    "(https://stats.idre.ucla.edu/r/dae/robust-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rlm function in the MASS package estimates robust regression.\n",
    "\n",
    "We will also use the fit.models function to display both regular and robust regression results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.models::fmclass.add.class(\"lmfm\", \"rlm\")\n",
    "\n",
    "fm1 <- fit.models::fit.models(c(\"rlm\", \"lm\"),\n",
    "                              y_train ~ L1 + B2 + T,\n",
    "                              data = data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick visual inspection of the estimated coefficient does not real any significant differences between regular regression (lm) and robust regression (rlm).\n",
    "\n",
    "We could test for a difference statistically if we saw a large difference, but won’t bother in this case.\n",
    "\n",
    "It appears the identified “outlying”observations are not sufficiently different from the underlying sample for us to remove\n",
    "them from our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast::ggAcf(fit2$residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, there are spikes.\n",
    "\n",
    "We can check autocorrelation with Durbin-Watson test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtest::dwtest(y_train ~ L1 + B2 + T, data = data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value, at 0.63, indicates there is no evidence of correlatedresiduals.\n",
    "\n",
    "It confirms our earlier observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 2:**\n",
    "\n",
    "Assess the predictive power of the model on the test set. You may use rmse and mae measures using TSrepr package, or scatterplots or any other method you would like from the first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "622.8px",
    "left": "0px",
    "right": "1312px",
    "top": "135.2px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
