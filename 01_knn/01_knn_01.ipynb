{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NEAREST NEIGHBOURS (KNN) WITH WISCONSIN BREAST CANCER DIAGNOSTIC DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This exercise is adapted from [Chapter 3 of \"Machine Learning with R\" by Brett Lantz](https://books.google.com.tr/books?id=ZaJNCgAAQBAJ&printsec=frontcover&hl=tr&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false)\n",
    "\n",
    "- In this exercise we will utilize the Wisconsin Breast Cancer Diagnostic dataset from the UCI\n",
    "Machine Learning Repository at http://archive.ics.uci.edu/ml.\n",
    "\n",
    "\n",
    "- The dataset includes the measurements from digitized images of fine-needle aspirate of a breast mass. The\n",
    "values represent the characteristics of the cell nuclei present in the digital image.\n",
    "\n",
    "\n",
    "- The breast cancer data includes 569 examples of cancer biopsies, each with\n",
    "32 features. One feature is an identification number, another is the cancer diagnosis,\n",
    "and 30 are numeric-valued laboratory measurements. The diagnosis is coded as\n",
    "\"M\" to indicate malignant or \"B\" to indicate benign. The other 30 numeric measurements comprise the mean, standard error, and worst (that is, largest) value for 10 different characteristics of the digitized cell nuclei.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These include:\n",
    "\n",
    "- Radius\n",
    "- Texture\n",
    "- Perimeter\n",
    "- Area\n",
    "- Smoothness\n",
    "- Compactness\n",
    "- Concavity\n",
    "- Concave points\n",
    "- Symmetry\n",
    "- Fractal dimension\n",
    "\n",
    "Based on these names, all the features seem to relate to the shape and size of the cell\n",
    "nuclei. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to continue from a previously saved session state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionfile <- \"01_knn_01.RData\"\n",
    "\n",
    "if(file.exists(sessionfile)) load(sessionfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load the libraries necessary for this exercise and define some useful options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table) # to handle the data in a more convenient manner\n",
    "library(tidyverse) # for a better work flow and more tools to wrangle and visualize the data\n",
    "library(BBmisc) # for easy normalization of data\n",
    "library(class) # for kNN classification algorithm \n",
    "library(gmodels) # for model evaluation\n",
    "library(plotly) # for interactive visualization\n",
    "options(warn=-1) # for suppressing messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data into a data.frame/data.table \"wbcd\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd <- data.table::fread(\"../data/csv/01_01_wisc_bc_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the structure of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(wbcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"diagnosis\" column is of type character. The rest are numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the id column, so we can drop it:\n",
    "Note that we use the in-place modification facility of data.tables.\n",
    "\n",
    "As a data.table, wbcd offers the ease of handling columnwise operations inside the braces - hence in a more concise and efficient manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd[,id:=NULL] # drop 1st column of data.table in-place (without assignment)\n",
    "\n",
    "# We could also do it as wbcd[,1=NULL] but that wouldn't be \"idempotent\": \n",
    "# Erroneously executing the cell a second time would delete the next column\n",
    "\n",
    "# wbcd <- wbcd[-1] # this is the usual data.frame way with assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See \"id\" is dropped from column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# .SD is a shortcut for all columns.\n",
    "# So this is, \"return the names of all columns\"\n",
    "wbcd[,names(.SD)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a better understanding of the variable names.\n",
    "\n",
    "Note the use of the \"pipe\" operator from the \"tidyverse\" suite of packages.\n",
    "\n",
    "It redirects the output of the former statement into the first argument of the latter statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of variables except the first,\n",
    "# And split the names from the underscore into a list of 30 items:\n",
    "splitnames <- wbcd[,names(.SD)][-1] %>% strsplit(\"_\")\n",
    "str(splitnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the first index of each list item and reduce into unique values\n",
    "sapply(splitnames, \"[\", 1) %>% unique()\n",
    "\n",
    "# get only the second index of each list item and reduce into unique values\n",
    "sapply(splitnames, \"[\", 2) %>% unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have in fact 10 variables with 3 different measurements for each (mean, se - \"for standart error\" and worst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome we try to predict is diagnosis. It would be nice to see the distribution of this categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wbcd[,table(diagnosis)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better that we recode diagnosis variable with more informative labels:\n",
    "Note that splitting long lines is a good coding practice for better readability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd[,diagnosis:=factor(diagnosis,\n",
    "                       levels = c(\"B\", \"M\"),\n",
    "                       labels = c(\"Benign\", \"Malignant\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can check the new labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd[,levels(diagnosis)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the percentages of each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd[,round(prop.table(table(diagnosis)) * 100, digits = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustrative purposes, let's get the statistical summary for three selected variables' \"mean\" measurements:\n",
    "\n",
    "Note that, to compute the summary on multiple selected columns, we define a placeholder \".SDcols\" to hold the names of selected columns. Now \".SD\" refers only to those selected columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd[,summary(.SD),\n",
    "     .SDcols = c(\"radius_mean\", \"area_mean\", \"smoothness_mean\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in the scales of variables may distort the \"distance\" calculation, the step at the heart of the kNN algorithm.\n",
    "\n",
    "So we must normalize the variables so that they have the same scales.\n",
    "\n",
    "We will follow the \"min-max normalization\" approach: The minimum value in all variables will be 0, and the maximum value will be 1.\n",
    "\n",
    "We can write a custom function as such:\n",
    "\n",
    "```r\n",
    "normalize <- function(x) {\n",
    "return ((x - min(x)) / (max(x) - min(x)))\n",
    "}\n",
    "```\n",
    "\n",
    "However, the power of R comes from the ability to reuse functions from the vast corpus of packages. We will utilize the \"normalize\" function from BBmisc package. This function can handle various normalization methods and options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize all variables except the first column to 0-1 range and save into new object\n",
    "\n",
    "wbcd_n <- wbcd[,BBmisc::normalize(.SD, \"range\"), .SDcols = -1]\n",
    "wbcd_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check whether the variables are really normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary statistics of area_mean\n",
    "wbcd_n[,summary(area_mean)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's determine the number of observations in the dataset.\n",
    "\n",
    "In data table .N is a placeholder for number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd_n[,.N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into two pieces as \"train\" and \"test\" sets.\n",
    "\n",
    "We holdout last 100 rows to test the predictive accuracy of the model. No need the refer to the end row of the train set explicitly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude last 100 rows and create train set\n",
    "wbcd_train <- wbcd_n[1:(.N - 100),]\n",
    "\n",
    "# confirm the dimensions\n",
    "dim(wbcd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign last 100 rows into test set\n",
    "wbcd_test <- wbcd_n[.N - 99:0,]\n",
    "\n",
    "# confirm the dimensions\n",
    "dim(wbcd_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use the labels from the diagnosis variable and split them into train and test also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd_train_labels <- wbcd[1:(.N - 100)][[1]]\n",
    "class(wbcd_train_labels)\n",
    "length(wbcd_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd_test_labels <- wbcd[.N - 99:0][[1]]\n",
    "class(wbcd_test_labels)\n",
    "length(wbcd_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should select an arbitrary \"k\" value - the count of nearest neighbours to vote for labeling\n",
    "\n",
    "It should be odd in order to prevent tie vote situations\n",
    "\n",
    "We go for \"21\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note some style preferences in the below code:\n",
    "\n",
    "- Although unnecessary when a package is loaded and has a namespace, functions should be explicitly called with their namespaces(packages) as such: \"class::knn\" for future reference (otherwise it would be hard to track which package a called function comes from)\n",
    "\n",
    "- operators like \"=\" should be surrounded by spaces for easy readability\n",
    "\n",
    "- Splitting function parameters in multiple lines enhances readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model on train and test datasets, train label and \"k\" value\n",
    "wbcd_test_pred <- class::knn(train = wbcd_train,\n",
    "                            test = wbcd_test,\n",
    "                            cl = wbcd_train_labels,\n",
    "                            k = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(wbcd_test_pred)\n",
    "length(wbcd_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the output of the model is a factor vector of diagnosis labels with the length of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should evaluate the model performance: Did our model perform well in identifying the labels of the test set correctly?\n",
    "\n",
    "We just compare the \"true\" labels of the test set with the \"predicted\" labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 <- gmodels::CrossTable(x = wbcd_test_labels,\n",
    "                   y = wbcd_test_pred,\n",
    "                   prop.chisq = F)\n",
    "ct1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Top left and bottom right quadrants indicate test cases which are correctly identified as Benign or Malignant\n",
    "Top right and bottom left quadrants indicate test cases which are misidentified\n",
    "\n",
    "Now with a small R hack, we can report the findings of the above table interactively (so in case data or methodology changes, the reporting will be updated automatically):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get diagnosis labels\n",
    "labels <- toupper(wbcd[,levels(diagnosis)])\n",
    "\n",
    "# false correct vector\n",
    "cf <- toupper(c(\"falsely\", \"correctly\"))\n",
    "\n",
    "# Create a data frame of result reports\n",
    "df1 <- data.frame(as.vector(outer(1:2, 1:2, Vectorize(function(x,y) sprintf(\"%s %s test cases are %s predicted as %s\",\n",
    "                                                           ct1$t[x,y],\n",
    "                                                          labels[x],\n",
    "                                                            cf[(x == y) + 1],\n",
    "                                                          labels[y])))))\n",
    "# Define a name for the report:               \n",
    "colnames(df1)[1] <- sprintf(\"Out of %s test cases: \", testn <- wbcd_test[,.N])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-max normalization, extreme values are compressed to 0-1 range.\n",
    "\n",
    "With z-score standardization, outliers are better expressed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd_z <- wbcd[,BBmisc::normalize(.SD), .SDcols = -1]\n",
    "wbcd_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, \"scale\" function from the base yields the same result, however that will coerce the data.table to a matrix, which we do not want for further analysis.\n",
    "\n",
    "BBmisc::normalize keeps the data.table class of the object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see whether variables are z-score normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd_z[,summary(area_mean)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the steps again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd_train <- wbcd_z[1:(.N - 100),]\n",
    "wbcd_test <- wbcd_z[.N - 99:0,]\n",
    "\n",
    "# the labels did not change so we do not need the following steps:\n",
    "wbcd_train_labels <- wbcd[1:(.N - 100)][[1]]\n",
    "wbcd_test_labels <- wbcd[.N - 99:0][[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model on train and test datasets, train label and \"k\" value\n",
    "wbcd_test_pred <- class::knn(train = wbcd_train,\n",
    "                            test = wbcd_test,\n",
    "                            cl = wbcd_train_labels,\n",
    "                            k = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 <- gmodels::CrossTable(x = wbcd_test_labels,\n",
    "                   y = wbcd_test_pred,\n",
    "                   prop.chisq = F)\n",
    "ct1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame of result reports\n",
    "df1 <- data.frame(as.vector(outer(1:2, 1:2, Vectorize(function(x,y) sprintf(\"%s %s test cases are %s predicted as %s\",\n",
    "                                                           ct1$t[x,y],\n",
    "                                                          labels[x],\n",
    "                                                            cf[(x == y) + 1],\n",
    "                                                          labels[y])))))\n",
    "# Define a name for the report:               \n",
    "colnames(df1)[1] <- sprintf(\"Out of %s test cases: \", testn <- wbcd_test[,.N])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, FALSE negative cases increased with z-score standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing alternative k values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the optimum k value, we should run a simulation of the model against a range of k values.\n",
    "\n",
    "For this, we combine all steps into a function and call it with sapply for multiple k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_batch <- function(kval = 21)\n",
    "{\n",
    "    # run prediction model\n",
    "    wbcd_test_pred1 <- class::knn(train = wbcd_train,\n",
    "                            test = wbcd_test,\n",
    "                            cl = wbcd_train_labels,\n",
    "                            k = kval)\n",
    "    \n",
    "    # count false negatives using boolean functions and comparing actual and predicted labels\n",
    "    false_neg <- sum(wbcd_test_labels == \"Malignant\" & wbcd_test_pred1 == \"Benign\")\n",
    "\n",
    "    # count false positives using boolean functions and comparing actual and predicted labels\n",
    "    false_pos <- sum(wbcd_test_labels == \"Benign\" & wbcd_test_pred1 == \"Malignant\")\n",
    "    \n",
    "    # report findings\n",
    "    c(kval, false_neg, false_pos, false_neg + false_pos)\n",
    "\n",
    "}\n",
    "\n",
    "# run the model for all k = 1 to 100\n",
    "report <- t(sapply(1:100, k_batch))\n",
    "\n",
    "# change column names\n",
    "colnames(report)  <- c(\"k value\", \"False negatives\", \"False positives\", \"Total classified incorrectly\")\n",
    "\n",
    "# return the matrix object\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize the relationship between k value and model performance\n",
    "\n",
    "- Plot total incorrect on y axis against k value on x axis\n",
    "- Show as dashed lines\n",
    "- The points should be smaller and blue except the point with minimum incorrect value which should be larger and red\n",
    "- Total number of incorrect labelings should be shown as tooltip when hovered over points with the mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# object should a data frame, not a matrix\n",
    "df1 <- as.data.frame(report)\n",
    "\n",
    "# create ggplot object with line and point geoms, point color and sizes and tooltip text\n",
    "# note the vectorized \"ifelse\" function to create vectors of colors and sizes\n",
    "gp <- ggplot2::ggplot(df1, aes(x = `k value`, y = `Total classified incorrectly` )) +\n",
    "geom_line(linetype = \"dashed\") +\n",
    "geom_point(color = ifelse(df1[[4]] == min(df1[[4]]), \"red\", \"blue\"),\n",
    "        size = ifelse(df1[[4]] == min(df1[[4]]), 6, 2),\n",
    "        mapping = aes(text = paste(\"k value: \", df1[[1]], \"\\n\", \"incorrect: \", df1[[4]]))) +\n",
    "        labs(x = \"k value\", y = \"total incorrect\")\n",
    "\n",
    "# Convert to plotly object for interactive tooltip\n",
    "plotly::ggplotly(gp, tooltip = c(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interactively interpret the above chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprintf(\"So, when the k value is %s, count of incorrect is at a minimum of %s\",\n",
    "        which.min(report[,4]),\n",
    "        min(report[,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save.image(sessionfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
