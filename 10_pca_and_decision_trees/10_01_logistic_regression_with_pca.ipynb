{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION AND PCA WITH CRAB DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from Lewis (2017), Chapter 7\n",
    "\n",
    "We will import a dataset from MASS package, including information on crabs and we will try to classify them as male vs. female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table) # to handle the data in a more convenient manner\n",
    "library(tidyverse) # for a better work flow and more tools to wrangle and visualize the data\n",
    "library(plotly) # for interactive visualizations\n",
    "library(corrplot) # for correlation plots\n",
    "library(psych) # for visualizing relationship among pairs of variables and PCA\n",
    "library(GPArotation) # for rotation of components in PCA\n",
    "library(GGally) # for better visualizing relationship among pairs of variables\n",
    "library(listviewer) # for visualizing nested data structures\n",
    "library(MASS) # for crab dataset\n",
    "library(pROC) # for ROC curve\n",
    "library(ROCR) # another library for ROC curve\n",
    "library(plotROC) # for pretty plot ROC curve\n",
    "library(IRdisplay) # for displaying interactive ROC curves\n",
    "library(gains) # for lift charts\n",
    "library(caret) # for lift charts and confusion matrix\n",
    "library(lift) # for decile life chart\n",
    "options(warn = -1) # for suppressing messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows=20, repr.matrix.max.cols=15) # for limiting the number of top and bottom rows of tables printed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath <- \"~/data_ad454\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(\"crabs\", package = \"MASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt <- as.data.table(crabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?crabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This data frame contains the following columns:\n",
    "\n",
    "sp\n",
    "species - \"B\" or \"O\" for blue or orange.\n",
    "\n",
    "sex\n",
    "as it says.\n",
    "\n",
    "index\n",
    "index 1:50 within each of the four groups.\n",
    "\n",
    "FL\n",
    "frontal lobe size (mm).\n",
    "\n",
    "RW\n",
    "rear width (mm).\n",
    "\n",
    "CL\n",
    "carapace length (mm).\n",
    "\n",
    "CW\n",
    "carapace width (mm).\n",
    "\n",
    "BD\n",
    "body depth (mm).\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(crabs_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt[,index := NULL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View initial rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore and visualize factor variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt %>% purrr::keep(is.factor) %>% purrr::map(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_factors <- crabs_dt %>% purrr::keep(is.factor) %>% # select factor columns\n",
    "    tidyr::gather() %>% # convert into long format for faceting\n",
    "    ggplot(aes(x = value)) + # plot value\n",
    "    facet_wrap(~ key, scales = \"free\") + # divide into separate plots by key\n",
    "    geom_bar()\n",
    "\n",
    "plotly::ggplotly(crabs_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's explore and visualize numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt %>% purrr::keep(is.numeric) %>% sapply(quantile) %>% t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt %>% purrr::keep(is.numeric) %>% # select columns\n",
    "    tidyr::gather() %>% # reshape into long format in columns \"key\" and \"value\"\n",
    "    ggplot(aes(value)) + # plot value\n",
    "        facet_wrap(~ key, scale = \"free\" ) + # divide into separate plots by key\n",
    "        geom_density(fill = \"green\")  # get density plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships among features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the correlation plot across numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt %>% purrr::keep(is.numeric) %>% cor() %>%\n",
    "\n",
    "corrplot::corrplot.mixed(upper = \"ellipse\",\n",
    "                         lower = \"number\",\n",
    "                         tl.pos = \"lt\",\n",
    "                         number.cex = .5,\n",
    "                         lower.col = \"black\",\n",
    "                         tl.cex = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that many variables are highly correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine, histograms, density plots, correlations and scatterplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt %>% purrr::keep(is.numeric) %>% psych::pairs.panels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt %>% purrr::keep(is.numeric) %>% GGally::ggpairs() %>% ggplotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y will be the target variable: The labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y <- crabs$sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 150 indices for train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2018)\n",
    "train <- crabs_dt[,sample(.I, 150)]\n",
    "head(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And split the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train <- y[train]\n",
    "y_test <- y[-train]\n",
    "\n",
    "crabs_train <- crabs_dt[train]\n",
    "crabs_test <- crabs_dt[-train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to linear regression, logistic regression assumes the features are independent.\n",
    "\n",
    "We saw earlier that there is high correlation between the features.\n",
    "\n",
    "Given this, we will fit our initial model using FL, RW, and the categorical variable sp.\n",
    "\n",
    "The logistic regression can be fitted to the sample data using the glm function, with the family argument set to binomial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula1 <- reformulate(c(\"sp\", \"FL\", \"RW\"), \"y_train\")\n",
    "formula1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 <- glm(formula1,\n",
    "            family=binomial(link='logit'),\n",
    "            data=crabs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the summary of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fit1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviance residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the residual in a linear regression model, the deviance residuals are a measure of model fit.\n",
    "\n",
    "Smaller absolute values indicate better fit. This part of the output shows minimum, quantiles, and the maximum of the deviance residuals for individual sample examples used to fit the model. The maximum deviance is 2.143, with a very small median value of -0.00255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fit1)$deviance.resid %>% summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fit1)$coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated coefficients are shown in the next part of the output.\n",
    "\n",
    "They indicate that FL influences crab sex positively, while sp and RW have a negative effect.\n",
    "\n",
    "The estimated values tell us the change in the log odds of the target variable for a one unit increase in a feature variable.\n",
    "\n",
    "As an example, for a one unit increase in FL, the log odds of being a male crab (versus female) increases by 3.725. \n",
    "\n",
    "However, for a one unit increase in RW, the log odds of being a male crab decreases by 5.11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Statistical significance of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confint.default(fit1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logistic models, R reports the confidence intervals using\n",
    "the profiled log-likelihood function.\n",
    "\n",
    "To see these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confint(fit1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since none of the confidence intervals straddle 0, we can have some empirically grounded certainty that the sign of the estimated coefficients captures the direction of the relationship of the features to the log odds of being a male crab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute value of the z-score is often used to measure variable importance.\n",
    "\n",
    "In this case, RW with an absolute value of 5.286, followed by FL with an absolute value of 5.160 are the most influential features.\n",
    "\n",
    "This is useful to know, and makes sense because both features are related to body size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fit1)$coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null and residual deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual deviance is analogous to the residual sum of squares of a linear regression model.\n",
    "\n",
    "Lower values indicate better fit.\n",
    "\n",
    "It takes a value of 58.703.\n",
    "\n",
    "The null deviance reports how well the target variable is predicted by a model that includes only the intercept.\n",
    "\n",
    "We would expect our model to do better than this.\n",
    "\n",
    "In this case it does, as the null deviance = 207.917.\n",
    "\n",
    "This implies our model has reduced the deviance by just over 149 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1$deviance\n",
    "fit1$null.deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and Fisher scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two items are also reported via the summary function:\n",
    "\n",
    "- The Akaike Information Criterion (AIC) is a measure of the relative quality of statistical models. It is only useful for comparing models.\n",
    "- The “Number of Fisher Scoring” iterations simply tells you how many iterations were needed to fit the model by maximum likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1$aic\n",
    "fit1$iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well our model fits, depends on the difference between the model and the observed data.\n",
    "\n",
    "One approach to evaluate this is to use the anova function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(fit1 , test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anova function adds the features in the order given in the model formula (left to right).\n",
    "\n",
    "Hence, sp appears first followed by FL and RW.\n",
    "\n",
    "Analyzing the table, we observe a small drop in deviance when adding each sp and FL. For example, adding sp, reduces the deviance from the Null model’s value of 207.917 to 207.485.\n",
    "\n",
    "This is a tiny drop. We see a similar pattern for adding in FL.\n",
    "\n",
    "In this case, the model deviance drops by 0.533 to 206.951."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition of these two variables moves the model deviation in the right directions (downward).\n",
    "\n",
    "However, as indicated by the large p-value (Pr(>Chi)) on both sp and FL, the change in not statistically significant\n",
    "\n",
    "This indicates the model without these variables explains approximately the same amount of variation\n",
    "\n",
    "Fortunately, adding the feature, RW leads to a significant reduction in deviance of over 148 points\n",
    "\n",
    "A highly significant p-value here, supports the importance of this feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo R<sup>2</sup> statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo R statistic for logistic regression.\n",
    "\n",
    "The pseudo-R2 is a useful goodness-of-fit metric for logistic regression.\n",
    "\n",
    "Similar to the traditional R2 statistic, it takes a value between 0 and 1. It is calculated as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\text{pseudo } R^{2}} = 1- \\frac{\\text{model deviance}}{{\\text{Null deviance}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (fit1$deviance / fit1$null.deviance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer to 1 is the metric, the more useful are the features in predicting the target variable\n",
    "\n",
    "In statistical language, it is more a measure of effect size than overall fit\n",
    "\n",
    "In any case, the value of 0.717 indicates that the model is useful for predicting crab sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model discrimination, ROC, and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discrimination of a model – that is, how well the model separates male from female crabs - can also be assessed using the area under the receiver operating characteristic curve (AUC)\n",
    "\n",
    "It uses two metrics, Specificity and Sensitivity.\n",
    "\n",
    "Specificity is a measure of how often the model predicts “female”(y = 0) when the actual observation is “female crab”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\text{Specificity}} = \\frac{\\text{True Negatives}}{{\\text{Total Negatives}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity or true positive rate measures when it’s actually “male”, how often does the model predict “male”\n",
    "\n",
    "$${\\text{Sensitivity}} = \\frac{\\text{True Positives}}{{\\text{Total Positives}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity and Sensitivity are often combined via a Receiver Operating Characteristic Curve (ROC).\n",
    "\n",
    "The ROC visually measures how well the predictive model separates the data into positives and negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ROC](https://www.researchgate.net/publication/8636163/figure/fig2/AS:202684352208899@1425335123086/Four-ROC-curves-with-different-values-of-the-area-under-the-ROC-curve-A-perfect-test-A.png)\n",
    "\n",
    "Four ROC curves with different values of the area under the ROC curve:\n",
    "- A perfect test (A) has an area under the ROC curve of 1.\n",
    "- The chance diagonal (D, the line segment from 0, 0 to 1, 1) has an area under the ROC curve of 0.5.\n",
    "- ROC curves of tests with some ability to distinguish between those subjects with and those without a disease (B, C) lie between these two extremes.\n",
    "- Test B with the higher area under the ROC curve has a better overall diagnostic performance than test C.\n",
    "\n",
    "(https://www.researchgate.net/figure/Four-ROC-curves-with-different-values-of-the-area-under-the-ROC-curve-A-perfect-test-A_fig2_8636163)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve with pROC package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get the predicted probability values for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred1 <- predict(fit1 , type=\"response\")\n",
    "\n",
    "as.data.table(pred1) %>%\n",
    "ggplot(aes(x = seq_along(pred1), y = pred1)) +\n",
    "xlab(\"Index\") +\n",
    "geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since levels are given as 1 for F and 2 for M (probably alphabetically), the predicted values are the probabilities of being M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a roc object for predicted probability values and the actual class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc <- pROC::roc(y_train, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train set data gave a value of 0.9067, indicating that the model discriminates well\n",
    "\n",
    "The confidence interval can be called using the ci function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pROC::ci(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ROC curve with base plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fancier option is from plotROC package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- data.table(D = y_train, M = pred1) %>%\n",
    "ggplot(aes(m = M, d = D)) +\n",
    "    plotROC::geom_roc() +\n",
    "    plotROC::style_roc(theme = theme_grey)\n",
    "\n",
    "p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or an interactive version of the same plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotROC::export_interactive_roc(p1) %>% IRdisplay::display_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer the curve is to the perfect classifier, the better it is at identifying positive \n",
    "values. This can be measured using a statistic known as the area under the ROC \n",
    "curve (abbreviated AUC). The AUC treats the ROC diagram as a two-dimensional \n",
    "square and measures the total area under the ROC curve. AUC ranges from 0.5 (for \n",
    "a classifier with no predictive value) to 1.0 (for a perfect classifier). A convention to \n",
    "interpret AUC scores uses a system similar to academic letter grades:\n",
    "\n",
    "- A: Outstanding = 0.9 to 1.0\n",
    "- B: Excellent/good = 0.8 to 0.9\n",
    "- C: Acceptable/fair = 0.7 to 0.8\n",
    "- D: Poor = 0.6 to 0.7\n",
    "- E: No discrimination = 0.5 to 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pROC::auc(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC is outstanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve with ROCR library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from Lantz (2015) Chapter 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a prediction object, taking into account the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ROCR <- ROCR::prediction(predictions = pred1,\n",
    "                             labels = y_train,\n",
    "                             label.ordering = c(\"F\", \"M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then a performance object for true positives vs false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf <- ROCR::performance(pred_ROCR,\n",
    "                            measure = \"tpr\",\n",
    "                            x.measure = \"fpr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(perf, lwd = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For AUC calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_auc <- ROCR::performance(pred_ROCR, measure = \"auc\")\n",
    "perf_auc@y.values %>% unlist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some applications, the goal is to search, among a set of new records, for a subset of records that gives the highest cumulative predicted values.\n",
    "\n",
    "In such cases, a graphical way to assess predictive performance is through a lift chart.\n",
    "\n",
    "This compares the model’s predictive performance to a baseline model that has no predictors.\n",
    "\n",
    "A lift chart for a continuous response is relevant only when we are searching for a set of records that gives the highest cumulative predicted values.\n",
    "\n",
    "A lift chart is not relevant if we are interested in predicting the outcome value for each new record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lift chart is based on ordering the set of records of interest (typically validation data) by their predicted value, from high to low.\n",
    "\n",
    "Then, we accumulate the actual values and plot their cumulative value on the y-axis as a function of the number of records accumulated (the x-axis value).\n",
    "\n",
    "This curve is compared to assigning a naive prediction (y) to each record and accumulating these average values, which results in a diagonal line.\n",
    "\n",
    "The further away the lift curve from the diagonal benchmark line, the better the model is doing in separating records\n",
    "with high value outcomes from those with low value outcomes.\n",
    "\n",
    "The same information can be presented in a decile lift chart, where the ordered records are grouped into ten deciles, and for each decile, the chart presents the ratio of model lift to naive benchmark lift.\n",
    "\n",
    "(Shmueli (2017) Chapter 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lift chart with gains package and ggplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a gains object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain <- gains::gains(as.numeric(y_train) - 1,\n",
    "                        pred1,\n",
    "                        groups = length(pred1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the lift chart, we should take the first 11 elements from gain and convert to a data frame object in order to plot with ggplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as.data.frame(gain[1:11]) %>%\n",
    "ggplot(aes(x = cume.obs / max(cume.obs), y = cume.pct.of.total)) +\n",
    "geom_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lift chart with caret and ggplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better option is to use the lift() function from the caret package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift1 <- caret::lift(y_train ~ pred1)\n",
    "lift1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the function took the F class as the positive case while in our model M is the positive (predicted) case. We change the factor levels for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift1 <- caret::lift(y_train %>% forcats::fct_relevel(\"M\") ~ pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's view the percent table of class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(y_train) %>% prop.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the lift curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift1 %>%\n",
    "ggplot(plot = \"gain\") %>% plotly::ggplotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret this plot:\n",
    "\n",
    "The dashed line at the top is the ideal case where classification accuracy is 100%\n",
    "\n",
    "The dark line is the plot for the model\n",
    "\n",
    "The dashed line at the bottom is the pure random case and is the baseline\n",
    "\n",
    "The observations are sorted by probabilities. The x axis shows the percent of cases covered, y axis shows the percent of positive class found in those cases.\n",
    "\n",
    "Since the percent of positive class is 49.3, in the best case the line will have a smooth upward slope until x reaches 49.3 and y reaches 100%. After that no more positive cases are left so the line will be horizontal.\n",
    "\n",
    "In the random case, 100% of positive cases will be found only when 100% of samples are tested\n",
    "\n",
    "We see that the model line follows the best line until 36.7% of all cases are tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decile lift by lift package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to look at the lift chart is to look at each subsequent decile of observations, and what portion of the positive cases are caught with the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift::plotLift(pred1, as.numeric(y_train) - 1, n.buckets = 10, cumulative = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift::TopDecileLift(pred1, as.numeric(y_train) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value of 2.027 means, when 10% of all observations are tested 20.27% of all positive cases are found "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert log odd values to class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_train_f <- factor(ifelse(pred1 > 0.5, \"M\", \"F\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1_train <- table(y_train, pred1_train_f) %>% caret::confusionMatrix()\n",
    "cm1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy is 0.9067"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets predict the probability values for the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_test <- predict(fit1,\n",
    "                      newdata = crabs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And convert them to class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predclass1_test <- ifelse(pred1_test > 0.5, \"M\", \"F\") %>% factor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1_test <- table(y_test, predclass1_test) %>% caret::confusionMatrix()\n",
    "cm1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an accuracy of 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Components Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the relationships among numeric variables again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt %>% purrr::keep(is.numeric) %>% cor() %>%\n",
    "\n",
    "corrplot::corrplot.mixed(upper = \"ellipse\",\n",
    "                         lower = \"number\",\n",
    "                         tl.pos = \"lt\",\n",
    "                         number.cex = .5,\n",
    "                         lower.col = \"black\",\n",
    "                         tl.cex = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crabs_dt %>% purrr::keep(is.numeric) %>% GGally::ggpairs() %>% ggplotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What stands out is the very high correlation between the attributes.\n",
    "\n",
    "This is not surprising as they are all measurements related to body\n",
    "size.\n",
    "\n",
    "However, it violates the assumption that features are independent.\n",
    "\n",
    "What to do?\n",
    "\n",
    "One solution is to use the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA with base-r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prcomp function calculates the principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca <- crabs_dt %>%\n",
    "    purrr::keep(is.numeric) %>%\n",
    "    prcomp(center = T,\n",
    "           scale = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA components are linear combinations of the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at the PCA coefficient weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca$rotation %>% round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See whether components are orthagonal (uncorrelated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(pca$x) %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, cross correlations are near zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proportion of variance explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of variation explained by each principal component can be viewed using the summary function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component explains 95.8% of the variation in the feature data, and the second component 3%\n",
    "\n",
    "Since, these two components account for over 98% of the variation in the data, we will use them as our independent variables in the logistic regression model.\n",
    "\n",
    "To do this we create a new R object called pca_dt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dt <- pca$x[,c(\"PC1\", \"PC2\")] %>% as.data.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA with psych package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from Lesmeister (2015), Chapter 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the components with the psych package, you will use the principal() function.\n",
    "\n",
    "We will state that we do not want to rotate the components at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 <- crabs_dt %>%\n",
    "    purrr::keep(is.numeric) %>%\n",
    "    psych::principal(nfactors = 5, rotate = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the components should we take?\n",
    "\n",
    "A good rule of thumb is to select the components that account for at least 70 percent of the total variance, which means that the variance explained by each of the selected components accounts for 70 percent of the variance explained by all the components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A visual technique is to do a scree plot.\n",
    "\n",
    "A scree plot can aid you in assessing the components that explain the most variance in the data.\n",
    "\n",
    "It shows the Component number on the x axis and their associated Eigenvalues on the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2$values %>% as.data.table() %>%\n",
    "    ggplot(aes(x = seq_along(.), y = .)) +\n",
    "        geom_line() +\n",
    "        xlab(\"Component\") +\n",
    "        ylab(\"Eigenvalues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you are looking in a scree plot is with eigenvalues that are greater than one and the point where the additional \n",
    "variance explained by a component does not differ greatly from one component to the next.\n",
    "\n",
    "In other words, it is the break point where the plot flattens out. In this, two components look pretty compelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's rotate the two components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "rotate\t\n",
    "\"none\", \"varimax\", \"quartimax\", \"promax\", \"oblimin\", \"simplimax\", and \"cluster\" are possible rotations/transformations of the solution. See fa for all rotations avaiable.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3 <- crabs_dt %>%\n",
    "    purrr::keep(is.numeric) %>%\n",
    "    psych::principal(nfactors = 2, rotate = \"simplimax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the component scores can be viewed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3$scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model with PCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train <- pca_dt[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 <- glm(y_train ~ .,\n",
    "           data = pca_train,\n",
    "           family = \"binomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2$coefficients %>% round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that both PC1 and PC2 influence crab sex positively\n",
    "\n",
    "For a one unit increase in PC1, the log odds of being a male crab (versus female) increases by 0.328\n",
    "\n",
    "However, notice for pca2 the effect size at 21.217 is many multiple times larger than that of pca1\n",
    "\n",
    "Such a large difference cannot be ignored\n",
    "\n",
    "Let’s take a look at the statistics, in terms of the confidence interval of the estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confint.default(fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fit2)$coefficients %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercept and PC1 are statistically not significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the overall performance of the model is to look at the null deviance and residual deviance\n",
    "\n",
    "Null deviance indicates how well the class is predicted by a model with nothing but the intercept\n",
    "\n",
    "We would expect such a model to be a poor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2$null.deviance %>% round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2$deviance %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite PC1 not being statistically significant, the null deviance of fit2 at 31.14 is considerably lower than for the null model\n",
    "\n",
    "Adding in our predictors decreased the deviance by just over 176 points\n",
    "\n",
    "You may also have noticed that fit2 deviance is lower than for fit1\n",
    "\n",
    "This indicates fit2 has a smaller prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1$deviance %>% round(2)\n",
    "fit2$deviance %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, how well the model fits on the train data:\n",
    "\n",
    "Get predictions for probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 <- predict(fit2, type = \"response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And convert to class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predclass2 <- ifelse(pred2 > 0.5, \"M\", \"F\") %>% factor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2_train <- table(y_train, predclass2) %>% caret::confusionMatrix()\n",
    "cm2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1_train$overall[\"Accuracy\"] %>% round(3)\n",
    "cm2_train$overall[\"Accuracy\"] %>% round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the roc curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 <- data.table(D = y_train, M = pred2) %>%\n",
    "ggplot(aes(m = M, d = D)) +\n",
    "    plotROC::geom_roc() +\n",
    "    plotROC::style_roc(theme = theme_grey)\n",
    "\n",
    "plotROC::export_interactive_roc(p2) %>% IRdisplay::display_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pROC::auc(y_train, pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the previous model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pROC::auc(y_train, pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its predictive power on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test <- pca_dt[-train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2_test <- predict(fit2,\n",
    "                     newdata = pca_test,\n",
    "                     type = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predclass2_test <- ifelse(pred2_test > 0.5, \"M\", \"F\") %>% factor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2_test <- table(y_test, predclass2_test) %>% caret::confusionMatrix()\n",
    "cm2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1_test$overall[\"Accuracy\"] %>% round(3)\n",
    "cm2_test$overall[\"Accuracy\"] %>% round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of predictions are also better for the 2nd model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop insignificant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PC1 was insignificant.\n",
    "\n",
    "Now let's only take PC2 as a predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit3 <- glm(y_train ~ PC2,\n",
    "           data = pca_train,\n",
    "           family = \"binomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predicted probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 <- predict(fit3, type = \"response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And factorize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predclass3 <- ifelse(pred3 > 0.5, \"M\", \"F\") %>% factor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3_train <- table(y_train, predclass3) %>% caret::confusionMatrix()\n",
    "cm3_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2_train$overall[\"Accuracy\"] %>% round(3)\n",
    "cm3_train$overall[\"Accuracy\"] %>% round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3_test <- predict(fit3,\n",
    "                     newdata = pca_test,\n",
    "                     type = \"response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predclass3_test <- ifelse(pred3_test > 0.5, \"M\", \"F\") %>% factor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3_test <- table(y_test, predclass3_test) %>% caret::confusionMatrix()\n",
    "cm3_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2_test$overall[\"Accuracy\"] %>% round(3)\n",
    "cm3_test$overall[\"Accuracy\"] %>% round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is better over model 2 and there is only one misclassification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "646.8px",
    "left": "0px",
    "right": "1312px",
    "top": "135.2px",
    "width": "273.4px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
